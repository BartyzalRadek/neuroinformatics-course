{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.keras as keras\n",
    "\n",
    "from tensorflow.contrib.keras import backend as K\n",
    "from tensorflow.contrib.keras.python.keras.models import Sequential\n",
    "from tensorflow.contrib.keras.python.keras.layers import Dense, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version = 1.3.0\n",
      "Python version = 3.5.2 (default, Nov 17 2016, 17:05:23) \n",
      "[GCC 5.4.0 20160609]\n",
      "Keras backend = tensorflow\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version =\", tf.__version__)\n",
    "#print(\"TF contrib Keras version =\",keras.__version__)\n",
    "print(\"Python version =\",sys.version)\n",
    "print(\"Keras backend =\", keras.backend.backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Unreasonable effectiveness of RNN: http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "Minimal char-rnn code: https://gist.github.com/karpathy/d4dee566867f8291f086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = open(filename, 'r').read() # should be simple plain text file\n",
    "    print(\"Loaded data from\", filename)\n",
    "    \n",
    "    chars = list(set(data))\n",
    "    data_size, vocab_size = len(data), len(chars)\n",
    "    print(\"Data has {} characters, {} unique.\".format(data_size, vocab_size))\n",
    "\n",
    "    char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "    ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "    print(\"Turn an array of characters to an array of numbers:\")\n",
    "    data_ix = [char_to_ix[char] for char in data]\n",
    "    print(\"  data[0]={} has been turned to: \\n  data_ix[0]={}\".format(data[0], data_ix[0]))\n",
    "\n",
    "    data_one_hot = np.zeros(shape=(data_size, vocab_size), dtype=float)\n",
    "    for i in range(len(data_ix)):\n",
    "        idx = data_ix[i]\n",
    "        data_one_hot[i,idx] = 1.0\n",
    "    print(\"Turn an array of numbers to an array of one-hot encoded vectors:\")\n",
    "    print(\"  data_ix[0]={} has been turned to: \\n  data_one_hot[0]={}\".format(data_ix[0], data_one_hot[0]))\n",
    "    print(\"Returning data_one_hot, data_size, vocab_size, ix_to_char\")\n",
    "    return data_one_hot, data_size, vocab_size, ix_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_char(vec, ix_to_char):\n",
    "    \"\"\"Returns most probable character represented by the 'one-hot' vector of probabilities.\"\"\"\n",
    "    return ix_to_char[np.argmax(vec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from data/first_names.txt\n",
      "Data has 36122 characters, 27 unique.\n",
      "Turn an array of characters to an array of numbers:\n",
      "  data[0]=J has been turned to: \n",
      "  data_ix[0]=9\n",
      "Turn an array of numbers to an array of one-hot encoded vectors:\n",
      "  data_ix[0]=9 has been turned to: \n",
      "  data_one_hot[0]=[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Returning data_one_hot, data_size, vocab_size, ix_to_char\n"
     ]
    }
   ],
   "source": [
    "data_one_hot, data_size, vocab_size, ix_to_char = load_data('data/first_names.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'J'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_to_char(data_one_hot[0], ix_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_1.3_Python3",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
